<!DOCTYPE html>
<html>
<head>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.0-latest/MathJax.js?config=TeX-MML-AM_HTMLorMML-full"> </script>

  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="A Human-AI Co-Creative Sound Artwork Using a Real-time Multi-channel Sound Generation Model">
  <meta property="og:title" content="Studies for"/>
  <meta property="og:description" content="A Human-AI Co-Creative Sound Artwork Using a Real-time Multi-channel Sound Generation Model"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/icon.jpg" />
  <meta property="og:image:width" content="2048"/>
  <meta property="og:image:height" content="1365"/>


  <meta name="twitter:title" content="Studies for">
  <meta name="twitter:description" content="A Human-AI Co-Creative Sound Artwork Using a Real-time Multi-channel Sound Generation Model">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/icon.jpg">
  <meta name="twitter:card" content="static/images/icon.jpg">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>SpecMaskFoley Demo Page</title>
  <link rel="icon" type="image/x-icon" href="static/images/icon.jpg">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">
  <!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css"> -->

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


<section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">‘Studies for’: A Human-AI Co-Creative Sound Artwork Using a Real-time Multi-channel Sound Generation Model</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
            <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=en&user=tAaGMqYAAAAJ" target="_blank">Chihiro Nagashima</a>,
            </span>
            <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=en&user=oKUpOaQAAAAJ" target="_blank">Akira Takahashi</a>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=en&user=iRVT3A8AAAAJ" target="_blank">Zhi Zhong</a>,
            </span>
            <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=en&user=_mhxayYAAAAJ" target="_blank">Shusuke Takahashi</a>,
            </span>
            <span class="author-block">
                <a href="https://www.yukimitsufuji.com/" target="_blank">Yuki Mitsufuji</a>,
            </span>
            </span>
            </div>
            <div class="is-size-5 publication-authors">
            <span class="author-block">Sony Group Corporation<br>
            <span class="author-block">
            <span class="author-block">
<!--                     <span class="eql-cntrb"><small><br><center><img src="static/images/cifar_badge.svg" alt="MY ALT TEXT" width="100%"/></center></small></span> -->
            </div>
            <div class="column has-text-centered">
            <div class="publication-links">
            <!-- ArXiv abstract Link -->
            <span class="link-block">
            <a href="https://arxiv.org/abs/2510.25228" target="_blank"
            class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
                <i class="ai ai-arxiv"></i>
            </span>
            <span>arXiv</span>
            </a>
            </span>
    </span>
    </div>
    </div>
          </div>
        </div>
      </div>
    </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                <p>
                  This paper explores the integration of AI technologies into the artistic workflow through the creation of Studies for, a generative sound installation developed in collaboration with sound artist Evala (https://www.ntticc.or.jp/en/archive/works/studies-for/). The installation employs SpecMaskGIT, a lightweight yet high-quality sound generation AI model, to generate and playback eight-channel sound in real-time, creating an immersive auditory experience over the course of a three-month exhibition. The work is grounded in the concept of a "new form of archive," which aims to preserve the artistic style of an artist while expanding beyond artists' past artworks by continued generation of new sound elements. This speculative approach to archival preservation is facilitated by training the AI model on a dataset consisting of over 200 hours of Evala’s past sound artworks.
                  By addressing key requirements in the co-creation of art using AI, this study highlights the value of the following aspects: (1) the necessity of integrating artist feedback, (2) datasets derived from an artist's past works, and (3) ensuring the inclusion of unexpected, novel outputs. In \emph{Studies for}, the model was designed to reflect the artist's artistic identity while generating new, previously unheard sounds, making it a fitting realization of the concept of "a new form of archive." We propose a Human-AI co-creation framework for effectively incorporating sound generation AI models into the sound art creation process and suggest new possibilities for creating and archiving sound art that extend an artist's work beyond their physical existence.
                </p>
                </div>
            </div>
        </div>
  </div>
</section>

<!-- Demo Video -->
<br>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="column is-max-desktop is-full-mobile">
     <div class="hero-body">
<!-- <section class="section hero">
  <div class="container is-full-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-max-desktop is-full-mobile">  -->
      <h2 id="section_1" class="title is-3">Demo Video</h2>
        <div class="table-container">
          <table class="table" align="center" style="table-layout: fixed; word-break: break-word; width: 100%;">
            <thead>
              <tr>
              </tr>
            </thead>

            <tbody>
              <tr>
                <td>
                    <video style="width: 100%; height: 100%; object-fit: cover;" controls>
                        <source src="static/videos/Studiesfor_fordemo.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
<!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Acknowledgements / Related Links</h2>

        <div class="content has-text-justified">
          <p>
            This work was realized through the generous collaboration of sound artist <a href="https://www.evala.jp/Profile">evala</a>
          </p>
          <p>
            It was exhibited at the <a href="https://www.ntticc.or.jp/en/archive/works/studies-for/">NTT InterCommunication Center [ICC]</a> in Tokyo, Japan, from December 14, 2024 to March 9, 2025.
          </p>
          <p>
            The videos on this website and the photos in the paper are courtesy of ICC.
          </p>
          <p>
            For more details about the sound generation model SpecMaskGIT used in this work, please see [<a href="https://arxiv.org/abs/2406.17672">link</a>].
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->
  </div>
</section>


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @inproceedings{chihiro2025studiesfor,
        title={‘Studies for’: A Human-AI Co-Creative Sound Artwork Using a Real-time Multi-channel Sound Generation Model},
        author={Chihiro, Nagashima and Takahashi, Akira and Zhong, Zhi and Takahashi, Shusuke and Mitsufuji, Yuki},
        booktitle={NeurIPS Creative AI Track 2025},
        year={2025}
        }
      </code></pre>
    </div>
</section>

<!--End BibTex citation -->


<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
